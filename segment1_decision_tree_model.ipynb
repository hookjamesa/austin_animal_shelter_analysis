{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import input dataset to dataframe (module 8.5.1, https://www.techtrekking.com/how-to-read-data-from-postgresql-to-pandas-dataframe/)\n",
    "engine = create_engine(db_string)\n",
    "db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/XXXXXXX\"\n",
    "\n",
    "animals_df = pd.read_sql(\"SELECT * FROM \\\"XXXXXX\\\"\", con=engine)\n",
    "animals_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session (link) from Python to the database\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import input dataset to dataframe (alternate) (https://kb.objectrocket.com/postgresql/execute-an-sql-statement-for-postgresql-using-python-856, https://stackoverflow.com/questions/17143132/python-psycopg2-postgres-select-columns-including-field-names)\n",
    "# try:\n",
    "#     # declare a new PostgreSQL connection object\n",
    "#     conn = connect (\n",
    "#         dbname = \"\",\n",
    "#         user = \"\",\n",
    "#         password = \"\",\n",
    "#         host = \"\",\n",
    "#         port = \"\"\n",
    "#     )\n",
    "\n",
    "#     # attempt to create a cursor object\n",
    "#     cursor = conn.cursor()\n",
    "#     cr.execute(\"SELECT * FROM XXXXXX;\")\n",
    "#     tmp = cr.fetchall()\n",
    "    \n",
    "#     # Extract column names\n",
    "#     col_names = []\n",
    "#     for elt in cr.decription:\n",
    "#         col_names.append(elt[0])\n",
    "#     # Create DataFrame passing in list of column names extracted from the description\n",
    "#     animals_df = pd.DataFrame(tmp, columns=col_names)\n",
    "\n",
    "# except Exception as err:\n",
    "    \n",
    "#     # set the cursor to None if exception\n",
    "#     cursor = None\n",
    "#     print (\"\\npsycopg2 error:\", err)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if the connection was valid\n",
    "# if cursor != None:\n",
    "#     print (\"\\nconnection successful:\", conn, \"\\n\")\n",
    "\n",
    "#     # get the table name from args\n",
    "#     if len(sys.argv) <= 1:\n",
    "#         print (\"Please pass a SQL string as an argument\")\n",
    "#         quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a categorical variable list\n",
    "animals_cat = animals_df.dtypes[loans_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "animals_df[animals_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(animals_df[animals_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(animals_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "animals_df = animals_df.merge(encode_df,left_index=True, right_index=True)\n",
    "animals_df = animals_df.drop(animals_cat,1)\n",
    "animals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = animals_df.copy()\n",
    "X = X.drop(\"animal_id_outcome\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target vector\n",
    "y = animals_df[\"animal_id_outcome\"].values.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Print array\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Fit the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree classifier instance\n",
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions from test data - ADD SCHEMA\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tree\n",
    "tree.plot_tree(predictions,\n",
    "              filled=True,\n",
    "              rounded=True,\n",
    "              fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "animals_cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "animals_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Confusion Matrix\")\n",
    "display(animals_cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
